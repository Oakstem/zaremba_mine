Model: GRU With Dropout
ModelGRU(
  (embedding): Embedding(10000, 200)
  (rnns): ModuleList(
    (0): GRU(200, 200)
    (1): GRU(200, 200)
  )
  (fc): Linear(in_features=200, out_features=10000, bias=True)
  (dropout): Dropout(p=0.5, inplace=False)
)
Epoch no = 1 / 39, lr = 1.000 , Norm = 6.639, Train loss = 5.986 , Train perplexity : 275.556 , Test perplexity : 279.945
Epoch no = 2 / 39, lr = 1.000 , Norm = 6.620, Train loss = 5.762 , Train perplexity : 196.184 , Test perplexity : 208.440
Epoch no = 3 / 39, lr = 1.000 , Norm = 6.565, Train loss = 5.625 , Train perplexity : 168.512 , Test perplexity : 186.445
Epoch no = 4 / 39, lr = 1.000 , Norm = 6.845, Train loss = 5.616 , Train perplexity : 159.951 , Test perplexity : 180.504
Epoch no = 5 / 39, lr = 1.000 , Norm = 6.964, Train loss = 5.523 , Train perplexity : 153.449 , Test perplexity : 175.598
Epoch no = 6 / 39, lr = 1.000 , Norm = 7.301, Train loss = 5.494 , Train perplexity : 148.506 , Test perplexity : 172.111
Epoch no = 7 / 39, lr = 0.833 , Norm = 7.287, Train loss = 5.440 , Train perplexity : 131.940 , Test perplexity : 158.466
Epoch no = 8 / 39, lr = 0.694 , Norm = 6.782, Train loss = 5.305 , Train perplexity : 124.077 , Test perplexity : 151.381
Epoch no = 9 / 39, lr = 0.579 , Norm = 6.709, Train loss = 5.237 , Train perplexity : 111.615 , Test perplexity : 140.282
Epoch no = 10 / 39, lr = 0.482 , Norm = 6.825, Train loss = 5.169 , Train perplexity : 105.305 , Test perplexity : 135.295
Epoch no = 11 / 39, lr = 0.402 , Norm = 6.664, Train loss = 5.071 , Train perplexity : 99.013 , Test perplexity : 130.185
Epoch no = 12 / 39, lr = 0.335 , Norm = 6.731, Train loss = 5.075 , Train perplexity : 94.035 , Test perplexity : 125.722
Epoch no = 13 / 39, lr = 0.279 , Norm = 6.771, Train loss = 5.082 , Train perplexity : 90.045 , Test perplexity : 122.424
Epoch no = 14 / 39, lr = 0.233 , Norm = 6.845, Train loss = 5.02 , Train perplexity : 87.568 , Test perplexity : 120.341
Epoch no = 15 / 39, lr = 0.194 , Norm = 7.024, Train loss = 5.011 , Train perplexity : 84.672 , Test perplexity : 118.411
Epoch no = 16 / 39, lr = 0.162 , Norm = 7.013, Train loss = 5.005 , Train perplexity : 82.813 , Test perplexity : 116.821
Epoch no = 17 / 39, lr = 0.135 , Norm = 7.133, Train loss = 4.956 , Train perplexity : 81.154 , Test perplexity : 115.037
Epoch no = 18 / 39, lr = 0.112 , Norm = 7.152, Train loss = 4.985 , Train perplexity : 79.742 , Test perplexity : 114.400
Epoch no = 19 / 39, lr = 0.093 , Norm = 7.111, Train loss = 4.935 , Train perplexity : 78.623 , Test perplexity : 113.547
Epoch no = 20 / 39, lr = 0.078 , Norm = 7.222, Train loss = 4.882 , Train perplexity : 77.659 , Test perplexity : 112.741
Epoch no = 21 / 39, lr = 0.065 , Norm = 7.210, Train loss = 4.924 , Train perplexity : 76.791 , Test perplexity : 111.970
Epoch no = 22 / 39, lr = 0.054 , Norm = 7.147, Train loss = 4.951 , Train perplexity : 76.278 , Test perplexity : 111.649
Epoch no = 23 / 39, lr = 0.045 , Norm = 7.397, Train loss = 4.890 , Train perplexity : 75.675 , Test perplexity : 111.027
Epoch no = 24 / 39, lr = 0.038 , Norm = 7.219, Train loss = 4.925 , Train perplexity : 75.233 , Test perplexity : 110.731
Epoch no = 25 / 39, lr = 0.031 , Norm = 7.337, Train loss = 4.879 , Train perplexity : 74.949 , Test perplexity : 110.504
Epoch no = 26 / 39, lr = 0.026 , Norm = 7.146, Train loss = 4.866 , Train perplexity : 74.528 , Test perplexity : 110.123
Epoch no = 27 / 39, lr = 0.022 , Norm = 7.319, Train loss = 4.916 , Train perplexity : 74.389 , Test perplexity : 110.004
Epoch no = 28 / 39, lr = 0.018 , Norm = 7.387, Train loss = 4.888 , Train perplexity : 74.067 , Test perplexity : 109.776
Epoch no = 29 / 39, lr = 0.015 , Norm = 7.356, Train loss = 4.915 , Train perplexity : 73.950 , Test perplexity : 109.704
Epoch no = 30 / 39, lr = 0.013 , Norm = 7.431, Train loss = 4.845 , Train perplexity : 73.786 , Test perplexity : 109.597
Epoch no = 31 / 39, lr = 0.010 , Norm = 7.187, Train loss = 4.865 , Train perplexity : 73.605 , Test perplexity : 109.327
Epoch no = 32 / 39, lr = 0.009 , Norm = 7.399, Train loss = 4.908 , Train perplexity : 73.490 , Test perplexity : 109.290
Epoch no = 33 / 39, lr = 0.007 , Norm = 7.262, Train loss = 4.843 , Train perplexity : 73.447 , Test perplexity : 109.284
Epoch no = 34 / 39, lr = 0.006 , Norm = 7.284, Train loss = 4.872 , Train perplexity : 73.333 , Test perplexity : 109.166
Epoch no = 35 / 39, lr = 0.005 , Norm = 7.454, Train loss = 4.913 , Train perplexity : 73.260 , Test perplexity : 109.081
Epoch no = 36 / 39, lr = 0.004 , Norm = 7.400, Train loss = 4.928 , Train perplexity : 73.244 , Test perplexity : 109.078
Epoch no = 37 / 39, lr = 0.004 , Norm = 7.326, Train loss = 4.898 , Train perplexity : 73.171 , Test perplexity : 109.039
Epoch no = 38 / 39, lr = 0.003 , Norm = 7.548, Train loss = 4.906 , Train perplexity : 73.116 , Test perplexity : 108.974
Epoch no = 39 / 39, lr = 0.002 , Norm = 7.320, Train loss = 4.914 , Train perplexity : 73.083 , Test perplexity : 108.974

Train Summary:

Train Perplexities :[   275.5556229522964, 196.18376880688692, 168.51249460833483, 159.95058182758433,
                        153.44931434670042, 148.50589040376798, 131.93955022751805, 124.07741126809336,
                        111.61505349613137, 105.3050836812622, 99.01325554363011, 94.0350564505705,
                        90.04458873224348, 87.56764379461715, 84.67226132512086, 82.81255800967861,
                        81.1537878647458, 79.74198269881042, 78.6225519066107, 77.65889959428435,
                        76.79078860092058, 76.27826986042345, 75.67535577322678, 75.23277349846542,
                        74.94926720000116, 74.52795051372556, 74.38880284186895, 74.06745240273963,
                        73.9504057179906, 73.7855195569325, 73.60507325389293, 73.48973341308243,
                        73.44742028510586, 73.3330489778141, 73.25981487558107, 73.24439214942149,
                        73.17135766701193, 73.11593811060425, 73.08290043493868 ]

Test Perplexities :[    279.94488674596073, 208.4399473334869, 186.44464282721523, 180.50376039701257,
                        175.59822291171469, 172.1113013898749, 158.4663069227081, 151.38093626032676,
                        140.28199438583098, 135.29507900574262, 130.18524952399778, 125.72240544129835,
                        122.42411488395965, 120.34050142558155, 118.41071591822063, 116.82095963976086,
                        115.03651051961798, 114.39994756553183, 113.54664514608231, 112.74128094949945,
                        111.97040025054548, 111.6492297338574, 111.02683375312883, 110.73068700909454,
                        110.5044647110096, 110.12257291091338, 110.00400785648081, 109.7761719875814,
                        109.70358144454778, 109.59705555656586, 109.32677396810213, 109.29019744506817,
                        109.28432168020589, 109.16565720351122, 109.08122923615467, 109.07758138311777,
                        109.03935934884247, 108.97357201811259, 108.97415471193307 ]
