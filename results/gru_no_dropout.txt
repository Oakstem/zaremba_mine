Model: GRU No Dropout
ModelGRU(
  (embedding): Embedding(10000, 200)
  (rnns): ModuleList(
    (0): GRU(200, 200)
    (1): GRU(200, 200)
  )
  (fc): Linear(in_features=200, out_features=10000, bias=True)
  (dropout): Dropout(p=0, inplace=False)
)
Epoch no = 1 / 39, lr = 1.000, Norm = 5.421, Train loss = 5.658, Train perplexity : 209.285, Test perplexity : 228.891
Epoch no = 2 / 39, lr = 1.000, Norm = 6.374, Train loss = 5.273, Train perplexity : 149.291, Test perplexity : 182.607
Epoch no = 3 / 39, lr = 1.000, Norm = 7.226, Train loss = 5.049, Train perplexity : 125.028, Test perplexity : 167.501
Epoch no = 4 / 39, lr = 1.000, Norm = 7.598, Train loss = 4.904, Train perplexity : 105.897, Test perplexity : 153.917
Epoch no = 5 / 39, lr = 1.000, Norm = 8.213, Train loss = 4.829, Train perplexity : 97.673, Test perplexity : 150.729
Epoch no = 6 / 39, lr = 1.000, Norm = 8.672, Train loss = 4.731, Train perplexity : 87.609, Test perplexity : 144.847
Epoch no = 7 / 39, lr = 0.833, Norm = 8.612, Train loss = 4.553, Train perplexity : 72.598, Test perplexity : 135.195
Epoch no = 8 / 39, lr = 0.694, Norm = 9.065, Train loss = 4.376, Train perplexity : 61.239, Test perplexity : 132.595
Epoch no = 9 / 39, lr = 0.579, Norm = 9.750, Train loss = 4.192, Train perplexity : 54.012, Test perplexity : 134.111
Epoch no = 10 / 39, lr = 0.482, Norm = 10.777, Train loss = 4.054, Train perplexity : 48.676, Test perplexity : 138.584
Epoch no = 11 / 39, lr = 0.402, Norm = 11.850, Train loss = 3.943, Train perplexity : 44.038, Test perplexity : 142.546
Epoch no = 12 / 39, lr = 0.335, Norm = 12.408, Train loss = 3.813, Train perplexity : 40.468, Test perplexity : 148.030
Epoch no = 13 / 39, lr = 0.279, Norm = 12.897, Train loss = 3.705, Train perplexity : 37.615, Test perplexity : 152.875
Epoch no = 14 / 39, lr = 0.233, Norm = 14.094, Train loss = 3.625, Train perplexity : 35.287, Test perplexity : 158.822
Epoch no = 15 / 39, lr = 0.194, Norm = 14.722, Train loss = 3.557, Train perplexity : 33.348, Test perplexity : 164.858
Epoch no = 16 / 39, lr = 0.162, Norm = 15.597, Train loss = 3.476, Train perplexity : 31.599, Test perplexity : 170.392
Epoch no = 17 / 39, lr = 0.135, Norm = 16.029, Train loss = 3.390, Train perplexity : 30.166, Test perplexity : 175.073
Epoch no = 18 / 39, lr = 0.112, Norm = 16.747, Train loss = 3.352, Train perplexity : 28.972, Test perplexity : 180.126
Epoch no = 19 / 39, lr = 0.093, Norm = 18.003, Train loss = 3.307, Train perplexity : 27.813, Test perplexity : 183.529
Epoch no = 20 / 39, lr = 0.078, Norm = 18.034, Train loss = 3.272, Train perplexity : 26.918, Test perplexity : 187.855
Epoch no = 21 / 39, lr = 0.065, Norm = 18.042, Train loss = 3.247, Train perplexity : 26.052, Test perplexity : 190.984
Epoch no = 22 / 39, lr = 0.054, Norm = 18.233, Train loss = 3.222, Train perplexity : 25.270, Test perplexity : 193.853
Epoch no = 23 / 39, lr = 0.045, Norm = 19.379, Train loss = 3.202, Train perplexity : 24.605, Test perplexity : 196.282
Epoch no = 24 / 39, lr = 0.038, Norm = 20.510, Train loss = 3.193, Train perplexity : 23.986, Test perplexity : 197.846
Epoch no = 25 / 39, lr = 0.031, Norm = 20.193, Train loss = 3.196, Train perplexity : 23.419, Test perplexity : 199.900
Epoch no = 26 / 39, lr = 0.026, Norm = 19.738, Train loss = 3.183, Train perplexity : 22.899, Test perplexity : 201.612
Epoch no = 27 / 39, lr = 0.022, Norm = 21.210, Train loss = 3.183, Train perplexity : 22.402, Test perplexity : 203.100
Epoch no = 28 / 39, lr = 0.018, Norm = 22.401, Train loss = 3.191, Train perplexity : 21.959, Test perplexity : 204.394
Epoch no = 29 / 39, lr = 0.015, Norm = 22.701, Train loss = 3.192, Train perplexity : 21.549, Test perplexity : 205.496
Epoch no = 30 / 39, lr = 0.013, Norm = 22.402, Train loss = 3.186, Train perplexity : 21.168, Test perplexity : 206.332
Epoch no = 31 / 39, lr = 0.010, Norm = 21.461, Train loss = 3.181, Train perplexity : 20.832, Test perplexity : 207.021
Epoch no = 32 / 39, lr = 0.009, Norm = 21.857, Train loss = 3.180, Train perplexity : 20.523, Test perplexity : 207.544
Epoch no = 33 / 39, lr = 0.007, Norm = 21.399, Train loss = 3.174, Train perplexity : 20.255, Test perplexity : 207.925
Epoch no = 34 / 39, lr = 0.006, Norm = 21.268, Train loss = 3.168, Train perplexity : 20.014, Test perplexity : 208.224
Epoch no = 35 / 39, lr = 0.005, Norm = 21.007, Train loss = 3.164, Train perplexity : 19.798, Test perplexity : 208.464
Epoch no = 36 / 39, lr = 0.004, Norm = 20.857, Train loss = 3.159, Train perplexity : 19.603, Test perplexity : 208.643
Epoch no = 37 / 39, lr = 0.004, Norm = 20.710, Train loss = 3.154, Train perplexity : 19.427, Test perplexity : 208.756
Epoch no = 38 / 39, lr = 0.003, Norm = 21.009, Train loss = 3.150, Train perplexity : 19.272, Test perplexity : 208.791
Epoch no = 39 / 39, lr = 0.002, Norm = 20.834, Train loss = 3.146, Train perplexity : 19.141, Test perplexity : 208.801
Train Summary:
Train Perplexities :[   209.28489740204205, 149.29120410187855, 125.0283660030791, 105.897291977539,
                        97.67303813294909, 87.60926404200089, 72.5976487412571, 61.23888360857082,
                        54.01229032639351, 48.67575154500578, 44.03830182956404, 40.46783355408325,
                        37.61453673080075, 35.28676812483791, 33.34759135948846, 31.599280108770362,
                        30.16577155221546, 28.971716775061516, 27.81348749662538, 26.917978516736724,
                        26.051953306681586, 25.269537435882032, 24.604630613734916, 23.98639481195882,
                        23.418544371363314, 22.899361326276043, 22.401753847769534, 21.95866228815109,
                        21.549081115213518, 21.16757520202368, 20.832005030224842, 20.522516678737453,
                        20.254621394481926, 20.01374521959676, 19.79810794489703, 19.602794059473638,
                        19.4269612753753, 19.272421360870364, 19.141058543867807 ]

Test Perplexities :[    228.89081505746915, 182.60744045129883, 167.50084388397158, 153.91728552667706,
                        150.72882129912534, 144.8474192224916, 135.19488319707048, 132.59453397692488,
                        134.1109887871593, 138.5844552762535, 142.54570524742147, 148.0301703427586,
                        152.874570165728, 158.8223595737317, 164.85756814567327, 170.39160014973393,
                        175.07301589051207, 180.12573732443212, 183.52946260348915, 187.85536891174937,
                        190.98432645906138, 193.85334325627076, 196.28243012102925, 197.8456136337204,
                        199.8996705620528, 201.61222864505376, 203.09975732093406, 204.39384285900496,
                        205.49612707454162, 206.33170108551172, 207.02080349778404, 207.5438721916849,
                        207.92486819533403, 208.22449282656768, 208.4638958736556, 208.6426592264145,
                        208.75576603412705, 208.7908909881958, 208.80144419555828 ]
